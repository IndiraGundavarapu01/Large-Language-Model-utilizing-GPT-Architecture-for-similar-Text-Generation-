{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndiraGundavarapu01/Large-Language-Model-utilizing-GPT-Architecture-for-similar-Text-Generation-/blob/main/GPTLanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!pip install Functional\n",
        "from torch.nn import functional as F'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u-Q7GIu_ep8p",
        "outputId": "14175287-0146-404d-9428-61120f9ab2c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!pip install Functional\\nfrom torch.nn import functional as F'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oSgAFHfwtWtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a5be07e-c379-4a19-dbb2-bb5d7b015701"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import os\\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX1vbe9HH6cL",
        "outputId": "03dad4c9-3303-46d5-94b1-4fccc031a93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import mmap\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)\n",
        "\n",
        "blockSize = 64\n",
        "batchSize = 128\n",
        "maxIters = 1000\n",
        "learningRate = 3e-4\n",
        "evalIters = 100 #reports the loss\n",
        "nEmbd = 384 #no of total dimensions we want to capture from concatenating all the heads\n",
        "n_head = 6 #heads in parallel\n",
        "nLayer = 6 #decoder blocks\n",
        "dropout = 0.2 #20% of neurons are dropped out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SI9oVX58H6cO",
        "outputId": "f8b2e398-f2b2-44da-d904-bba6e1c8380a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429014\n"
          ]
        }
      ],
      "source": [
        "#dataloader\n",
        "chs = \"\"\n",
        "with open('/content/Picture of dorian gray.txt', 'r', encoding = 'utf-8') as f:\n",
        "          text = f.read()\n",
        "          chs = sorted(list(set(text))) #reading the file as text\n",
        "\n",
        "print(len(text)) #length of file\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f9ZUtGKzHw6",
        "outputId": "c2e48955-e333-4209-ff6a-d51f9607aea7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lUeuChylH6cO",
        "outputId": "9b7541f2-cc18-496f-b5f0-572c7dcea569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The Picture of Dorian Gray\n",
            "\n",
            "by Oscar Wilde\n",
            "\n",
            "\n",
            "THE PREFACE\n",
            "\n",
            "\n",
            "The artist is the creator of beautiful things. To reveal art and\n",
            "conceal the artist is artâ€™s aim. The critic is he who can translate\n",
            "into another manner or a new material his impression of beautiful\n",
            "things.\n",
            "\n",
            "The highest as the lowest form o\n"
          ]
        }
      ],
      "source": [
        "print(text[:300]) #first 300 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jBWrIniOH6cP",
        "outputId": "a8f204a6-48d3-4586-e0de-2adfdb056db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(len(chs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0h2Yj1vTH6cP"
      },
      "outputs": [],
      "source": [
        "vocabSize = len(chs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EwS2lmZ-H6cP",
        "outputId": "dd72b10b-fe91-4520-8ed6-fbfb244e6213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"char_to_int = {char: idx for idx, char in enumerate(chs)}\\nint_to_char = {idx: char for idx, char in enumerate(chs)}\\ndef encode(s):\\n    return [char_to_int[char] for char in s]\\ndef decode(int_list):\\n    return ''.join([int_to_char[idx] for idx in int_list])\\n\\nencodedHello = encode('hello')\\ndecodedHello = decode(encodedHello)\\nprint(decodedHello)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#tokenizer\n",
        "'''char_to_int = {char: idx for idx, char in enumerate(chs)}\n",
        "int_to_char = {idx: char for idx, char in enumerate(chs)}\n",
        "def encode(s):\n",
        "    return [char_to_int[char] for char in s]\n",
        "def decode(int_list):\n",
        "    return ''.join([int_to_char[idx] for idx in int_list])\n",
        "\n",
        "encodedHello = encode('hello')\n",
        "decodedHello = decode(encodedHello)\n",
        "print(decodedHello)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DtJDV9LKH6cP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d963c2-d685-4da1-f36b-e3c5c52528e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0,  0,  0, 33, 48, 45,  1, 41, 58, 60, 49, 59, 60,  1, 49,\n",
            "        59,  1, 60, 48, 45,  1, 43, 58, 45, 41, 60, 55, 58,  1, 55, 46,  1, 42,\n",
            "        45, 41, 61, 60, 49, 46, 61, 52,  1, 60])\n"
          ]
        }
      ],
      "source": [
        "#using pytorch ML framework\n",
        "char_to_int = {char: idx for idx, char in enumerate(chs)}\n",
        "int_to_char = {idx: char for idx, char in enumerate(chs)}\n",
        "def encode(s):\n",
        "    return [char_to_int[char] for char in s]\n",
        "def decode(int_list):\n",
        "    return ''.join([int_to_char[idx] for idx in int_list])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype = torch.long)\n",
        "print(data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cHXyfOrUH6cQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1395bb6b-5fb9-4df3-97d7-15cbc5673aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "tensor([[49, 60, 48,  ..., 44, 49, 53],\n",
            "        [54, 46, 55,  ..., 58, 55, 61],\n",
            "        [ 1, 61, 59,  ..., 61, 47, 48],\n",
            "        ...,\n",
            "        [ 1, 48, 41,  ..., 48, 45,  1],\n",
            "        [45,  1, 53,  ..., 53, 59, 45],\n",
            "        [ 3,  1, 60,  ..., 42, 61, 60]], device='cuda:0')\n",
            "targets:\n",
            "tensor([[60, 48,  1,  ..., 49, 53,  1],\n",
            "        [46, 55, 58,  ..., 55, 61, 47],\n",
            "        [61, 59,  1,  ..., 47, 48, 60],\n",
            "        ...,\n",
            "        [48, 41, 44,  ..., 45,  1, 63],\n",
            "        [ 1, 53, 41,  ..., 59, 45, 52],\n",
            "        [ 1, 60, 61,  ..., 61, 60, 52]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#splitting\n",
        "n = int(0.8*len(data))\n",
        "trainData = data[:n]\n",
        "testData = data[n:]\n",
        "'''def getRandomChunk(split):\n",
        "    filename = \"/content/drive/MyDrive/output_train.txt\" if split == 'train' else \"/content/drive/MyDrive/output_val.txt\"\n",
        "    with open(filename, 'rb') as f: #opening in binary mode\n",
        "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
        "            # Determine the file size and a random position to start reading\n",
        "            fileSize = len(mm)\n",
        "            startPos = random.randint(0, (fileSize) - blockSize*batchSize)\n",
        "\n",
        "            # Seek to the random position and read the block of text\n",
        "            mm.seek(startPos)\n",
        "            block = mm.read(blockSize*batchSize-1)\n",
        "\n",
        "            # Decode the block to a string, ignoring any invalid byte sequences\n",
        "            decodedBlock = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
        "\n",
        "            # Train and test splits\n",
        "            data = torch.tensor(encode(decodedBlock), dtype=torch.long)\n",
        "\n",
        "    return data'''\n",
        "\n",
        "\n",
        "def getBatch(split):\n",
        "  #data = getRandomChunk(split)\n",
        "  idx = torch.randint(len(data) - blockSize, (batchSize,)) #batchsize is shape\n",
        "  #print(idx)\n",
        "  x = torch.stack([data[i:i+blockSize] for i in idx])\n",
        "  y = torch.stack([data[i+1:i+blockSize+1] for i in idx])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x,y\n",
        "\n",
        "x, y = getBatch(\"train\")\n",
        "print(\"inputs:\")\n",
        "print(x)\n",
        "print(\"targets:\")\n",
        "print(y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": true,
        "id": "uABMVkB4H6cR",
        "outputId": "5bc156d5-893a-47b2-ee2e-5a439b666874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context : tensor([0]) target : tensor(33)\n",
            "context : tensor([ 0, 33]) target : tensor(48)\n",
            "context : tensor([ 0, 33, 48]) target : tensor(45)\n",
            "context : tensor([ 0, 33, 48, 45]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1]) target : tensor(29)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29]) target : tensor(49)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49]) target : tensor(43)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43]) target : tensor(60)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60]) target : tensor(61)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61]) target : tensor(58)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58]) target : tensor(45)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1]) target : tensor(55)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55]) target : tensor(46)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1]) target : tensor(17)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17]) target : tensor(55)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55]) target : tensor(58)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58]) target : tensor(49)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49]) target : tensor(41)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41]) target : tensor(54)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1]) target : tensor(20)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20]) target : tensor(58)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58]) target : tensor(41)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41]) target : tensor(65)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0]) target : tensor(42)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42]) target : tensor(65)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1]) target : tensor(28)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28]) target : tensor(59)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59]) target : tensor(43)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43]) target : tensor(41)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41]) target : tensor(58)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1]) target : tensor(36)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36]) target : tensor(49)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49]) target : tensor(52)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52]) target : tensor(44)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44]) target : tensor(45)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0]) target : tensor(33)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33]) target : tensor(21)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21]) target : tensor(18)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1]) target : tensor(29)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29]) target : tensor(31)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31]) target : tensor(18)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18]) target : tensor(19)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19]) target : tensor(14)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14]) target : tensor(16)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16]) target : tensor(18)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0,  0]) target : tensor(0)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0,  0,  0]) target : tensor(33)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0,  0,  0, 33]) target : tensor(48)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0,  0,  0, 33, 48]) target : tensor(45)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0,  0,  0, 33, 48, 45]) target : tensor(1)\n",
            "context : tensor([ 0, 33, 48, 45,  1, 29, 49, 43, 60, 61, 58, 45,  1, 55, 46,  1, 17, 55,\n",
            "        58, 49, 41, 54,  1, 20, 58, 41, 65,  0,  0, 42, 65,  1, 28, 59, 43, 41,\n",
            "        58,  1, 36, 49, 52, 44, 45,  0,  0,  0, 33, 21, 18,  1, 29, 31, 18, 19,\n",
            "        14, 16, 18,  0,  0,  0, 33, 48, 45,  1]) target : tensor(41)\n"
          ]
        }
      ],
      "source": [
        "#bigram - knows current caharacter and just predicts the next one\n",
        "x = trainData[:blockSize]\n",
        "y = trainData[1:blockSize+1]\n",
        "\n",
        "for z in range(blockSize):  #for loop to show the target and predictions\n",
        "    context = x[:z+1]\n",
        "    target = y[z]\n",
        "    print(\"context :\", context, \"target :\", target) #sequential'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "H0-B83h9H6cR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b570eff-b6ae-460d-f9fa-801f8a3ce9ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429014\n"
          ]
        }
      ],
      "source": [
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimateLoss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(evalIters)\n",
        "    for k in range(evalIters):\n",
        "      X, Y = getBatch(split)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "t7AThl756qb2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing neural networks\n",
        "class Head(nn.Module):\n",
        "  \"\"\"one head of self-attenton\"\"\"\n",
        "  def __init__(self, headSize):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(nEmbd, headSize, bias = False) #converting 394 to 96\n",
        "    self.query = nn.Linear(nEmbd, headSize, bias = False)\n",
        "    self.value = nn.Linear(nEmbd, headSize, bias = False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(blockSize, blockSize)))\n",
        "    #self.tril = nn.Parameter(torch.tril(torch.ones(blockSize, blockSize)).view(1, blockSize, blockSize), requires_grad=False)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #input of size (batch, time-step, channels)\n",
        "    #output of size( batch, time-step, headsize)\n",
        "    B,T,C = x.shape #breaking the x\n",
        "    k = self.key(x) # changing channel to headsize -> (B,T,C) becomes (B,T,hs)\n",
        "    q = self.query(x) #  (B,T,C) becomes (B,T,hs)\n",
        "    #compute attention scores(\"affinities\")\n",
        "    wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 #(B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) #(B, T, T)\n",
        "    wei = F.softmax(wei, dim = -1) # exponentiates the masked weights to make the model more confident to score better in long run when we highlight what tokens and attention scores are more important\n",
        "    wei = self.dropout(wei)\n",
        "    #perform final matrix mul for weighted aggregation of values\n",
        "    v = self.value(x) #(B, T, hs)\n",
        "    out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "    return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"multiple heads of self attention in parallel\"\"\"\n",
        "  def __init__(self, numHeads, headSize):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(headSize) for _ in range(numHeads)]) #4 heads running in parallel\n",
        "    self.proj = nn.Linear(headSize*numHeads, nEmbd) #if we wnat to change it, it wont throw dimensionality errors if we mention speciically, adds another learnable parameter\n",
        "    self.dropout = nn.Dropout(dropout) #drops 20% of network neurons\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.cat([h(x) for h in self.heads], dim = -1) #concatenate each head together along last dimension, last dimension is #(B, T, C), so we will concatenate by channel C also known as(feature) dimension\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  \"\"\"a simple linear layer followed by a non-linearity\"\"\"\n",
        "\n",
        "  def __init__(self, nEmbd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(nEmbd, 4*nEmbd),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4*nEmbd, nEmbd), #output shape will be nEmbd*nEmbd\n",
        "        nn.Dropout(dropout), #makes some neurons drop out and become zero to prevent overfitting\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "  \"\"\"Transformer block: communication followed by computation\"\"\"\n",
        "\n",
        "  def __init__(self, nEmbd, n_head): #nEmbd = embedding dimension, n_head - the number of heads we would like\n",
        "    super().__init__() #initializing things we do in the forward pass\n",
        "    headSize = nEmbd//n_head #how many features is ecah head capturing = 394/4 = 96\n",
        "    self.sa = MultiHeadAttention(n_head, headSize)# self attention\n",
        "    self.ffwd = FeedForward(nEmbd)#linear,relu,linear\n",
        "    self.ln1 = nn.LayerNorm(nEmbd)#postnorm\n",
        "    self.ln2 = nn.LayerNorm(nEmbd)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.sa(x) #slef attention\n",
        "    x = self.ln1(x+y) #add and norm\n",
        "    y = self.ffwd(x) #forward\n",
        "    x = self.ln2(x+y)#add and norm\n",
        "    return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "  def __init__(self, vocabSize):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocabSize, nEmbd) #kindof like a heat map giving the probability of a character coming next to another, we can claculate the propotions by normalizing the character number in the table by the sum entire line\n",
        "    self.position_embedding_table = nn.Embedding(blockSize, nEmbd)\n",
        "    self.blocks = nn.Sequential(*[Block(nEmbd, n_head = n_head) for _ in range(nLayer)]) #builds 4 layers of decoders\n",
        "    self.ln_f = nn.LayerNorm(nEmbd) #final layer norm (nn.Linear at end of decoder)\n",
        "    self.lm_head = nn.Linear(nEmbd, vocabSize)\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module): #initilization on weights\n",
        "    if isinstance(module, nn.Linear):\n",
        "      torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "      if module.bias is not None:\n",
        "        torch.nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "      torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
        "\n",
        "  def forward(self, index, targets=None): #writing a forward function helps in debugging and understanding behind the scenes of transformations\n",
        "    B, T = index.shape\n",
        "    #logits = self.token_embedding_table(index) #normalizing floating point numbers to get proportions of what comes next\n",
        "    #B, T, C = logits.shape # to understand logits shape, by B - BATCH, by T - TIME(sequence of integers, we dont know next token is so thats why we say it time, cause we dont know next), by C - channel(vocabsize), so logits shape is B*T*C\n",
        "\n",
        "\n",
        "    #idx and targets are both (B,T) tensor of integers\n",
        "    #B, T, C = logits.shape\n",
        "    tokEmb = self.token_embedding_table(index) #(B,T,C)\n",
        "    posEmb = self.position_embedding_table(torch.arange(T, device = device)) #(T,C), lookup table\n",
        "    x = tokEmb + posEmb #(B, T, C)\n",
        "    x = self.blocks(x) #(B, T, C)\n",
        "    x = self.ln_f(x) #(B, T, C)\n",
        "    logits = self.lm_head(x) #(B, T, vocabSize)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B,T,C = logits.shape\n",
        "      logits = logits.view(B*T, C) # blending Batch and Time together, since they are not as significant as batch, as long as logits and targets have the same batch in time, it should work\n",
        "      targets = targets.view(B*T) #view function is used to change shape, to unpack with .shape and repack with .view\n",
        "      loss = F.cross_entropy(logits, targets) #loss function, using entropy to measure it\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, index, maxNewTokens) :\n",
        "    for _ in range(maxNewTokens):\n",
        "      logits, loss = self.forward(index)\n",
        "      logits = logits[:, -1, :]\n",
        "      probs = F.softmax(logits, dim = -1)\n",
        "      indexNext = torch.multinomial(probs, num_samples=1)\n",
        "      index = torch.cat((index, indexNext), dim = 1)\n",
        "    return index\n",
        "\n",
        "model = GPTLanguageModel(vocabSize)\n",
        "\n",
        "'''with open('model1.pkl', 'rb') as f:\n",
        "  model = pickle.load(f)\n",
        "print(\"loaded parameters\")'''\n",
        "m = model.to(device)\n",
        "\n",
        "'''context = torch.zeros((1,1), dtype = torch.long, device = device)\n",
        "generatedChars = decode(m.generate(context, maxNewTokens = 500)[0].tolist())\n",
        "print(generatedChars)'''\n",
        "\n"
      ],
      "metadata": {
        "id": "c9oyTHApOSz0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cb0d559b-be0d-4144-bf01-fffc6be20b41"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'context = torch.zeros((1,1), dtype = torch.long, device = device)\\ngeneratedChars = decode(m.generate(context, maxNewTokens = 500)[0].tolist())\\nprint(generatedChars)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#view example\n",
        "\n",
        "#a = torch.rand(2,3,5)\n",
        "#x, y, z = a.shape # x= 2, y=3, z=5\n",
        "#a = a.view(x, y, z) #making tensor 'a' again with those dimensions\n",
        "#print(a.shape)\n",
        "\n",
        "#so we can unpack the tensor with .shape with use .view to put it together"
      ],
      "metadata": {
        "id": "hUF1Rv6zOSxd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a pytorch Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = learningRate)\n",
        "for iter in range(maxIters): #training loop\n",
        "  if iter %evalIters == 0:\n",
        "    losses = estimateLoss()\n",
        "    print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\") # to understand the losses for every couple of iterations to see if the model is actually doing better\n",
        "  xb, yb = getBatch('train') #inputs, targets\n",
        "\n",
        "  logits, loss = model.forward(xb, yb) #forward pass\n",
        "  optimizer.zero_grad(set_to_none=True) #define optimizer\n",
        "  loss.backward() #backward pass\n",
        "  optimizer.step() #gradient descent\n",
        "print(loss.item())\n",
        "\n",
        "#with open('model1.pkl', 'wb') as f:\n",
        " # pickle.dump(model, f)\n",
        "#default pytorch accumualtes the gradient by adding them\n",
        "#overtime but using zero gradient, set to non true, will not add the\n",
        "#previous gradients, so the previous gradients do not effect\n",
        "#the current one"
      ],
      "metadata": {
        "id": "CwUBbYAlOSvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c576ffbb-7953-4849-a5f6-8009fd096f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, train loss: 4.467, val loss: 4.466\n",
            "step: 100, train loss: 2.311, val loss: 2.314\n",
            "step: 200, train loss: 1.954, val loss: 1.951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from google.colab import files\n",
        "files.download('model1.pkl')'''\n"
      ],
      "metadata": {
        "id": "rsMbVAix8Fwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''#relu example\n",
        "x = torch.tensor([0.05], dtype = torch.float32)\n",
        "y = F.relu(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "MKP1coFBOSp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''#sigmoid example\n",
        "x = torch.tensor([-0.05], dtype = torch.float32)\n",
        "y = F.sigmoid(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "vcJeRkpuOSnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''#tanh example\n",
        "x = torch.tensor([1], dtype = torch.float32)\n",
        "y = F.tanh(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "oIr2nPkLOSh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fX98eVc1OSed"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cuda-gpt",
      "language": "python",
      "name": "cuda"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vp": {
      "vp_config_version": "1.0.0",
      "vp_menu_width": 273,
      "vp_note_display": false,
      "vp_note_width": 0,
      "vp_position": {
        "width": 278
      },
      "vp_section_display": false,
      "vp_signature": "VisualPython"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}